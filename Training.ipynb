{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from GNN_for_Depth.data.dataset import DepthDataset\n",
    "# from GNN_for_Depth.data.utils import custom_collate\n",
    "# from GNN_for_Depth.model.GNN import DepthGNNModel\n",
    "# from GNN_forDepth.utils.criterion import SiLogLoss\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "# from torchvision.ops import RoIAlign\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, glob\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch_geometric.data import Data\n",
    "import h5py, torch, cv2\n",
    "import numpy as np\n",
    "from statistics import mode\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn, optim\n",
    "\n",
    "\n",
    "\n",
    "class DepthDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data_path = \"/home3/fsml62/LLM_and_SGG_for_MDE/dataset/nyu_depth_v2/official_splits\", transform=None, ext=\"jpg\", mode='train', threshold=0.06):\n",
    "        \n",
    "        self.data_path = data_path\n",
    "        \n",
    "        self.filenames = glob.glob(os.path.join(self.data_path, mode, '**', '*.{}'.format(ext)), recursive=True)\n",
    "        self.pt_path = \"/home3/fsml62/LLM_and_SGG_for_MDE/GNN_for_MDE/results/depth_embedding/nyu_depth_v2/official_splits\"\n",
    "        self.depth_map_path = \"/home3/fsml62/LLM_and_SGG_for_MDE/GNN_for_MDE/results/depth_map/nyu_depth_v2/official_splits\"\n",
    "#         self.depth_map_path = \"/home3/fsml62/LLM_and_SGG_for_MDE/GNN_for_MDE/results/adabins/depth_map/nyu_depth_v2/official_splits\"\n",
    "        self.sg_path = \"/home3/fsml62/LLM_and_SGG_for_MDE/GNN_for_MDE/results/SGG/nyu_depth_v2/official_splits\"\n",
    "\n",
    "        self.transform = transform if transform else transforms.ToTensor()\n",
    "        self.mode = mode\n",
    "        self.threshold = threshold\n",
    "        \n",
    "        self.cache = {}\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        \n",
    "        if idx in self.cache:\n",
    "            return self.cache[idx]\n",
    "        \n",
    "\n",
    "        # image path\n",
    "        img_path = self.filenames[idx]\n",
    "        # get the image\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        # get the relative path\n",
    "        relative_path = os.path.relpath(img_path, self.data_path)\n",
    "        # get depth embedding path\n",
    "        depth_emb_path = os.path.join(self.pt_path, '{}.pt'.format(relative_path.split('.')[0]))\n",
    "        # get depth map path\n",
    "        depth_path = os.path.join(self.mode, self.depth_map_path, '{}.pt'.format(relative_path.split('.')[0]))\n",
    "\n",
    "        #get the scene graph path\n",
    "        scenegraph_path = os.path.join(self.sg_path, '{}.h5'.format(relative_path.split('.')[0]))\n",
    "\n",
    "\n",
    "\n",
    "        ## Depth Embedding\n",
    "        depth_emb = self.normalize(torch.load(depth_emb_path))\n",
    "\n",
    "        ## depth map\n",
    "        depth_map = self.normalize(torch.load(depth_path))\n",
    "\n",
    "        ## get the actual depth\n",
    "        actual_depth_path = img_path.replace(\"rgb\", \"sync_depth\").replace('.jpg', '.png')\n",
    "        actual_depth = Image.open(actual_depth_path)\n",
    "\n",
    "        \n",
    "        # the resize size\n",
    "        target_size = (25, 25)\n",
    "\n",
    "\n",
    "        with h5py.File(scenegraph_path, 'r') as h5_file:\n",
    "            loaded_output_dict = {key: torch.tensor(np.array(h5_file[key])) for key in h5_file.keys()}\n",
    "\n",
    "\n",
    "        probas = loaded_output_dict['rel_logits'].softmax(-1)[0, :, :-1]\n",
    "        probas_sub = loaded_output_dict['sub_logits'].softmax(-1)[0, :, :-1]\n",
    "        probas_obj = loaded_output_dict['obj_logits'].softmax(-1)[0, :, :-1]\n",
    "        \n",
    "        \n",
    "        keep = torch.logical_and(probas.max(-1).values > self.threshold, \n",
    "                                torch.logical_and(probas_sub.max(-1).values > self.threshold, probas_obj.max(-1).values > self.threshold))\n",
    "        \n",
    "        \n",
    "        \n",
    "      \n",
    "        \n",
    "        sub_bboxes_scaled = self.rescale_bboxes(loaded_output_dict['sub_boxes'][0, keep], img.size)\n",
    "        obj_bboxes_scaled = self.rescale_bboxes(loaded_output_dict['obj_boxes'][0, keep], img.size)\n",
    "        relations = loaded_output_dict['rel_logits'][0, keep]\n",
    "\n",
    "        valid_sub_bboxes = self.validate_bounding_boxes(sub_bboxes_scaled, img.size, target_size)\n",
    "        valid_obj_bboxes = self.validate_bounding_boxes(obj_bboxes_scaled, img.size, target_size)\n",
    "\n",
    "        # Combine validity of subject and object bounding boxes\n",
    "        valid_pairs = torch.tensor([vs and vo for vs, vo in zip(valid_sub_bboxes, valid_obj_bboxes)], dtype=torch.bool)\n",
    "\n",
    "        # Apply the updated keep mask\n",
    "        sub_bboxes_scaled = sub_bboxes_scaled[valid_pairs]\n",
    "        obj_bboxes_scaled = obj_bboxes_scaled[valid_pairs]\n",
    "        relations = relations[valid_pairs]\n",
    "        \n",
    "        \n",
    "        \n",
    "        sub_idxs, nodes1 = self.assign_index(sub_bboxes_scaled, [], threshold=0.7)\n",
    "        obj_idxs, nodes2 = self.assign_index(obj_bboxes_scaled, nodes1, threshold=0.7)\n",
    "        \n",
    "        all_idxs = sub_idxs + obj_idxs\n",
    "        bbox_lists = torch.concat((sub_bboxes_scaled, obj_bboxes_scaled), dim=0)\n",
    "        \n",
    "        unique_idxs = set()\n",
    "        filtered_idxs = []\n",
    "        filtered_bboxes = []\n",
    "\n",
    "        for idx, bbox in zip(all_idxs, bbox_lists):   \n",
    "            if idx not in unique_idxs:\n",
    "                unique_idxs.add(idx)\n",
    "                filtered_idxs.append(idx)\n",
    "                filtered_bboxes.append(bbox.tolist())  \n",
    "\n",
    "        # Sort the filtered indices along with their corresponding bounding boxes\n",
    "        sorted_wrapped = sorted(zip(filtered_idxs, filtered_bboxes), key=lambda x: x[0])\n",
    "        sorted_idxs, sorted_bboxes = zip(*sorted_wrapped)\n",
    "\n",
    "        # Convert them back to torch tensors\n",
    "        sorted_idxs = torch.tensor(sorted_idxs, dtype=torch.long)\n",
    "        sorted_bboxes = torch.tensor(sorted_bboxes, dtype=torch.int32)        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        # Apply transform to image and depth\n",
    "        img = self.transform(img)\n",
    "        img = self.normalize(img)\n",
    "        actual_depth = self.transform(actual_depth).float()\n",
    "        actual_depth = self.normalize(actual_depth)\n",
    "        depth_emb = self.normalize(depth_emb)\n",
    "        \n",
    "        device = 'cpu'\n",
    "        \n",
    "\n",
    "        pooled_images = self.linear_visual_content_and_depth(\n",
    "            sorted_bboxes=sorted_bboxes,\n",
    "            embedding=img,\n",
    "            target_size=target_size).to(device)\n",
    "        \n",
    "        pooled_depths = self.linear_visual_content_and_depth(\n",
    "            sorted_bboxes=sorted_bboxes,\n",
    "            embedding=depth_emb[0],\n",
    "            target_size=target_size).to(device)\n",
    "        \n",
    "        pooled_act_depths = self.resize_depth_map(\n",
    "            sorted_bboxes=sorted_bboxes,\n",
    "            embedding=actual_depth.squeeze(0),\n",
    "            target_size=target_size,\n",
    "            method='nearest').to(device)\n",
    "        \n",
    "        \n",
    "        \n",
    "        node_embeddings = torch.cat([pooled_images, pooled_depths], dim=1).to(device)\n",
    "        \n",
    "        edge_index = torch.tensor([sub_idxs, obj_idxs]).to(device)\n",
    "        \n",
    "        edge_embeddings = relations.clone().detach().float().to(device)\n",
    "        \n",
    "        \n",
    "        \n",
    "        gnndata = Data(x=node_embeddings, edge_index=edge_index, edge_attr=edge_embeddings)\n",
    "\n",
    "        ## return data\n",
    "        data = {\n",
    "            'image': img,\n",
    "            'depth_emb': depth_emb,\n",
    "            'depth_map': depth_map,\n",
    "            'depth': actual_depth,\n",
    "            'pooled_act_depths': pooled_act_depths,\n",
    "            'bboxs': filtered_bboxes,\n",
    "            'gnndata': gnndata\n",
    "        }\n",
    "        \n",
    "        self.cache[idx] = data\n",
    "        \n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "    \n",
    "    def box_cxcywh_to_xyxy(self, x):\n",
    "\n",
    "        x_c, y_c, w, h = x.unbind(1)\n",
    "        b = [(x_c - 0.5 * w), (y_c - 0.5 * h), (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
    "    \n",
    "        return torch.stack(b, dim=1)\n",
    "    \n",
    "    def rescale_bboxes(self, out_bbox, size):\n",
    "\n",
    "        img_w, img_h = size\n",
    "        b = self.box_cxcywh_to_xyxy(out_bbox)\n",
    "        b = b * torch.tensor([img_w, img_h, img_w, img_h], dtype=torch.float32)\n",
    "        \n",
    "        b = torch.round(b).int()\n",
    "\n",
    "        b[:, 0] = torch.clamp(b[:, 0], min=0, max=img_w)\n",
    "        b[:, 1] = torch.clamp(b[:, 1], min=0, max=img_h)\n",
    "        b[:, 2] = torch.clamp(b[:, 2], min=0, max=img_w)\n",
    "        b[:, 3] = torch.clamp(b[:, 3], min=0, max=img_h)\n",
    "\n",
    "        return b\n",
    "\n",
    "    def validate_bounding_boxes(self, bboxes, img_size, target_size):\n",
    "        \"\"\"Return a list of booleans indicating whether each bounding box is valid.\"\"\"\n",
    "        valid_bboxes = []\n",
    "        img_w, img_h = img_size\n",
    "        \n",
    "        t_w, t_h = target_size\n",
    "\n",
    "        for bbox in bboxes:\n",
    "            x1, y1, x2, y2 = bbox\n",
    "            if x1 < 0: x1 = 0\n",
    "            if y1 < 0: y1 = 0\n",
    "            if x2 > img_w: x2 = img_w\n",
    "            if y2 > img_h: y2 = img_h\n",
    "            \n",
    "            if (x2 - x1) >= t_w and (y2 - y1) >= t_h:\n",
    "                valid_bboxes.append(True)\n",
    "            else:\n",
    "                valid_bboxes.append(False)\n",
    "\n",
    "        return valid_bboxes\n",
    "\n",
    "\n",
    "    \n",
    "    def pool_visual_content_and_depth(self, sorted_bboxes, embedding, target_size=(50, 50)):\n",
    "\n",
    "        pool = nn.AdaptiveAvgPool2d(target_size)\n",
    "\n",
    "        pooled_embs = []\n",
    "\n",
    "        for bbox in sorted_bboxes:\n",
    "            cropped_emb = embedding[:, bbox[1]:bbox[3], bbox[0]:bbox[2]]\n",
    "\n",
    "            if cropped_emb.dim() == 2:\n",
    "                cropped_emb = cropped_emb.unsqueeze(0)  \n",
    "\n",
    "            pooled_emb = pool(cropped_emb.unsqueeze(0)).squeeze(0)\n",
    "\n",
    "            flattened_emb = pooled_emb.view(-1)\n",
    "            \n",
    "            pooled_embs.append(flattened_emb)\n",
    "\n",
    "\n",
    "        pooled_embs = torch.stack(pooled_embs) if pooled_embs else torch.empty(0)\n",
    "\n",
    "        return pooled_embs\n",
    "\n",
    "\n",
    "    def linear_visual_content_and_depth(self, sorted_bboxes, embedding, target_size=(50, 50)):\n",
    "\n",
    "        pooled_embs = []\n",
    "\n",
    "        for bbox in sorted_bboxes:\n",
    "\n",
    "            cropped_emb = embedding[:, bbox[1]:bbox[3], bbox[0]:bbox[2]]\n",
    "\n",
    "            if cropped_emb.dim() == 2:\n",
    "                cropped_emb = cropped_emb.unsqueeze(0)\n",
    "\n",
    "            pooled_emb = F.interpolate(cropped_emb.unsqueeze(0), size=target_size, mode='linear').squeeze(0)\n",
    "\n",
    "            flattened_emb = pooled_emb.view(-1)\n",
    "\n",
    "            pooled_embs.append(flattened_emb)\n",
    "\n",
    "        pooled_embs = torch.stack(pooled_embs) if pooled_embs else torch.empty(0)\n",
    "\n",
    "        return pooled_embs\n",
    "    \n",
    "    \n",
    "    def calculate_iou(self, box1, box2):\n",
    "\n",
    "        x1, y1, x2, y2 = box1\n",
    "        x3, y3, x4, y4 = box2\n",
    "\n",
    "        x_inter1 = max(x1, x3)\n",
    "        y_inter1 = max(y1, y3)\n",
    "        x_inter2 = min(x2, x4)\n",
    "        y_inter2 = min(y2, y4)\n",
    "\n",
    "        width_inter = max(0, x_inter2 - x_inter1)\n",
    "        height_inter = max(0, y_inter2 - y_inter1)\n",
    "\n",
    "        area_inter = width_inter * height_inter\n",
    "\n",
    "        width_box1 = abs(x2 - x1)\n",
    "        height_box1 = abs(y2 - y1)\n",
    "        area_box1 = width_box1 * height_box1\n",
    "\n",
    "        width_box2 = abs(x4 - x3)\n",
    "        height_box2 = abs(y4 - y3)\n",
    "        area_box2 = width_box2 * height_box2\n",
    "\n",
    "        area_union = area_box1 + area_box2 - area_inter\n",
    "\n",
    "        if area_union == 0:\n",
    "            return 0  # avoid division by zero\n",
    "        iou = area_inter / area_union\n",
    "\n",
    "        return iou\n",
    "    \n",
    "    \n",
    "    def assign_index(self, bounding_boxes, nodes, threshold=0.5):\n",
    "        indices = []\n",
    "        existing_boxes = nodes\n",
    "\n",
    "        for box in bounding_boxes:\n",
    "            found_match = False\n",
    "            for idx, existing_box in enumerate(existing_boxes):\n",
    "                if self.calculate_iou(box, existing_box) > threshold:\n",
    "                    indices.append(idx)\n",
    "                    found_match = True\n",
    "                    break\n",
    "\n",
    "            if not found_match:\n",
    "                existing_boxes.append(box)\n",
    "                indices.append(len(existing_boxes) - 1)\n",
    "\n",
    "        return indices, existing_boxes\n",
    "    \n",
    "    \n",
    "    def normalize(self, tensor):\n",
    "        tensor_min = tensor.min()\n",
    "        tensor_max = tensor.max()\n",
    "        normalized_tensor = (tensor - tensor_min) / ((tensor_max - tensor_min) + 1e-8)\n",
    "        return normalized_tensor\n",
    "    \n",
    "    \n",
    "    \n",
    "    def resize_depth_map(self, sorted_bboxes, embedding, target_size=(25, 25), method='nearest'):\n",
    "\n",
    "        pooled_embs = []\n",
    "\n",
    "        for bbox in sorted_bboxes:\n",
    "            cropped_emb = embedding[bbox[1]:bbox[3], bbox[0]:bbox[2]]\n",
    "\n",
    "            if method == 'nearest':\n",
    "                pooled_emb = self.downsize_depth_map_bilinear(cropped_emb, target_size)\n",
    "            else:\n",
    "                pooled_emb = self.downsize_depth_map_mode(cropped_emb, target_size)\n",
    "\n",
    "            flattened_emb = pooled_emb.view(-1)\n",
    "            \n",
    "            pooled_embs.append(flattened_emb)\n",
    "\n",
    "\n",
    "        pooled_embs = torch.stack(pooled_embs) if pooled_embs else torch.empty(0)\n",
    "\n",
    "        return pooled_embs\n",
    "    \n",
    "    \n",
    "    def downsize_depth_map_mode(self, depth_map, new_size):\n",
    "        \n",
    "        original_height, original_width = depth_map.shape[-2], depth_map.shape[-1]\n",
    "        new_height, new_width = new_size\n",
    "\n",
    "        window_height = original_height // new_height\n",
    "        window_width = original_width // new_width\n",
    "\n",
    "        downsized_map = torch.zeros((new_height, new_width), dtype=depth_map.dtype, device=depth_map.device)\n",
    "\n",
    "        for i in range(new_height):\n",
    "            for j in range(new_width):\n",
    "\n",
    "                start_row = i * window_height\n",
    "                end_row = start_row + window_height\n",
    "                start_col = j * window_width\n",
    "                end_col = start_col + window_width\n",
    "\n",
    "                window = depth_map[start_row:end_row, start_col:end_col]\n",
    "\n",
    "                flat_window = window.flatten().cpu().numpy()  \n",
    "\n",
    "                downsized_map[i, j] = mode(flat_window)\n",
    "\n",
    "        return downsized_map\n",
    "    \n",
    "    def downsize_depth_map_bilinear(self, depth_map, new_size):\n",
    "\n",
    "        if depth_map.dim() == 2:\n",
    "            depth_map = depth_map.unsqueeze(0).unsqueeze(0)  # Add batch and channel dimensions\n",
    "\n",
    "        new_height, new_width = new_size\n",
    "\n",
    "        resized_map = F.interpolate(depth_map, size=(new_height, new_width), mode='blinear')\n",
    "\n",
    "        return resized_map.squeeze(0).squeeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "util.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Batch, Data\n",
    "\n",
    "\n",
    "def custom_collate(batch):\n",
    "    \n",
    "    \n",
    "    batch = [item for item in batch if item is not None]\n",
    "\n",
    "    if len(batch) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Handle images, depth maps, and other tensors separately\n",
    "    images = torch.stack([item['image'] for item in batch])\n",
    "    depth_embs = torch.stack([item['depth_emb'] for item in batch])\n",
    "    depth_maps = torch.stack([item['depth_map'] for item in batch])\n",
    "    depths = torch.stack([item['depth'] for item in batch])\n",
    "    \n",
    "#     pooled_act_depths = [torch.tensor(item['pooled_act_depths'], dtype=torch.int) for item in batch]\n",
    "    pooled_act_depths = [item['pooled_act_depths'].clone().detach().float() for item in batch]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     bboxs = torch.stack([item['bboxs'] for item in batch])\n",
    "    bboxs = [torch.tensor(item['bboxs'], dtype=torch.int) for item in batch]\n",
    "\n",
    "    gnndata_list = [item['gnndata'] for item in batch]\n",
    "\n",
    "    # Batch the graph data using PyTorch Geometric's Batch\n",
    "    graph_batch = Batch.from_data_list(gnndata_list)\n",
    "\n",
    "    return {\n",
    "        'image': images,\n",
    "        'depth_emb': depth_embs,\n",
    "        'depth_map': depth_maps,\n",
    "        'depth': depths,\n",
    "        'pooled_act_depths': pooled_act_depths,\n",
    "        'bboxs': bboxs,\n",
    "        'gnndata': graph_batch,  # Batched graph data\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import MessagePassing\n",
    "import torch.nn as nn\n",
    "\n",
    "class DepthGNNModel(MessagePassing):\n",
    "    def __init__(self, node_features_size, edge_features_size, hidden_channels, output_size):\n",
    "        super(DepthGNNModel, self).__init__(aggr='add')\n",
    "\n",
    "        self.message_mlp = nn.Sequential(\n",
    "            nn.Linear(2 * node_features_size + edge_features_size, 1024),  # Reduced size\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(1024, hidden_channels)\n",
    "        )\n",
    "\n",
    "        self.node_mlp = nn.Sequential(\n",
    "            nn.Linear(node_features_size + hidden_channels, 2048),  # Reduced size\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(1024, output_size)  # Output a flattened 25x25 depth map\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "\n",
    "    def message(self, x_i, x_j, edge_attr):\n",
    "        message_input = torch.cat([x_i, edge_attr, x_j], dim=-1)\n",
    "        return self.message_mlp(message_input)\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        updated_node_features = torch.cat([x, aggr_out], dim=-1)\n",
    "        return self.node_mlp(updated_node_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the whole dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = './model_weights/current_linear_checkpoint.pth'\n",
    "\n",
    "def save_checkpoint(epoch, model, optimizer, path):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, path)\n",
    "\n",
    "def load_checkpoint(model, optimizer, path):\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    return checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = np.inf\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DepthDataset()\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=0, collate_fn=custom_collate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initialise model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, optimizer, and other components\n",
    "node_features_size =  41875 # 82075 # \n",
    "edge_features_size = 52\n",
    "hidden_channels = 728\n",
    "output_size = 625 #1225 # \n",
    "\n",
    "gnn_model = DepthGNNModel(node_features_size, edge_features_size, hidden_channels, output_size).cuda()\n",
    "# torch.nn.utils.clip_grad_norm_(gnn_model.parameters(), max_norm=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.multiprocessing as mp\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "\n",
    "#     mp.set_start_method('spawn', force=True)\n",
    "#     single_batch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.MSELoss()\n",
    "# optimizer = optim.Adam(gnn_model.parameters(), lr=1e-4)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
    "# # early_stopping = EarlyStopping(patience=5, min_delta=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gnndata = single_batch['gnndata'].to('cuda')\n",
    "# pooled_act_depths = [depth_map.cuda() for depth_map in single_batch['pooled_act_depths']]\n",
    "\n",
    "# output = gnn_model(gnndata.x, gnndata.edge_index, gnndata.edge_attr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# loss = 0\n",
    "# for i, node_output in enumerate(output):\n",
    "#     node_output_reshaped = node_output.view(-1, output_size)\n",
    "#     ground_truth = pooled_act_depths[0][i].view(-1, output_size)\n",
    "\n",
    "#     normalized_output = (node_output_reshaped - node_output_reshaped.min()) / (node_output_reshaped.max() - node_output_reshaped.min() + 1e-8)\n",
    "#     normalized_ground_truth = (ground_truth - ground_truth.min()) / (ground_truth.max() - ground_truth.min() + 1e-8)\n",
    "\n",
    "#     loss += criterion(normalized_output, normalized_ground_truth)\n",
    "\n",
    "# loss = loss / len(output)\n",
    "\n",
    "# if torch.isnan(loss):\n",
    "#     print(\"Loss became NaN. Stopping training.\")\n",
    "\n",
    "\n",
    "# # Backward\n",
    "# optimizer.zero_grad()\n",
    "# loss.backward()\n",
    "# optimizer.step()\n",
    "\n",
    "# # epoch_loss += loss.item()\n",
    "\n",
    "# # Print the loss for the epoch\n",
    "# # print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1536, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 795/795 [11:20<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Average Loss: 0.1385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|██████████| 795/795 [04:03<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Average Loss: 0.1376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|██████████| 795/795 [04:02<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Average Loss: 0.1368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|██████████| 795/795 [03:59<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Average Loss: 0.1349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|██████████| 795/795 [03:58<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Average Loss: 0.1318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|██████████| 795/795 [03:53<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Average Loss: 0.1285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|██████████| 795/795 [03:55<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Average Loss: 0.1258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|██████████| 795/795 [03:54<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Average Loss: 0.1243\n",
      "Checkpoint saved: ./model_weights/checkpoint_linear_epoch_8.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: 100%|██████████| 795/795 [03:54<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Average Loss: 0.1234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: 100%|██████████| 795/795 [03:56<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Average Loss: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: 100%|██████████| 795/795 [03:58<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Average Loss: 0.1220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: 100%|██████████| 795/795 [03:56<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Average Loss: 0.1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50: 100%|██████████| 795/795 [03:56<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Average Loss: 0.1182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50: 100%|██████████| 795/795 [03:56<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], Average Loss: 0.1165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50: 100%|██████████| 795/795 [03:57<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Average Loss: 0.1159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50: 100%|██████████| 795/795 [03:59<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Average Loss: 0.1149\n",
      "Checkpoint saved: ./model_weights/checkpoint_linear_epoch_16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50: 100%|██████████| 795/795 [03:58<00:00,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50], Average Loss: 0.1139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50: 100%|██████████| 795/795 [03:58<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], Average Loss: 0.1137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50: 100%|██████████| 795/795 [03:59<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50], Average Loss: 0.1128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50: 100%|██████████| 795/795 [03:58<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50], Average Loss: 0.1128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50: 100%|██████████| 795/795 [04:00<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50], Average Loss: 0.1108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50: 100%|██████████| 795/795 [03:59<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50], Average Loss: 0.1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50: 100%|██████████| 795/795 [04:02<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50], Average Loss: 0.1092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50: 100%|██████████| 795/795 [03:59<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50], Average Loss: 0.1081\n",
      "Checkpoint saved: ./model_weights/checkpoint_linear_epoch_24.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50: 100%|██████████| 795/795 [03:59<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50], Average Loss: 0.1076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50: 100%|██████████| 795/795 [04:00<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50], Average Loss: 0.1077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50: 100%|██████████| 795/795 [04:01<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50], Average Loss: 0.1067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50: 100%|██████████| 795/795 [03:59<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50], Average Loss: 0.1062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50: 100%|██████████| 795/795 [03:59<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50], Average Loss: 0.1057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50: 100%|██████████| 795/795 [03:57<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50], Average Loss: 0.1060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50: 100%|██████████| 795/795 [04:03<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50], Average Loss: 0.1048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50: 100%|██████████| 795/795 [03:59<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50], Average Loss: 0.1051\n",
      "Checkpoint saved: ./model_weights/checkpoint_linear_epoch_32.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50: 100%|██████████| 795/795 [03:58<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50], Average Loss: 0.1047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50: 100%|██████████| 795/795 [04:00<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50], Average Loss: 0.1039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/50: 100%|██████████| 795/795 [04:00<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50], Average Loss: 0.1036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/50: 100%|██████████| 795/795 [03:59<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50], Average Loss: 0.1038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/50: 100%|██████████| 795/795 [04:00<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50], Average Loss: 0.1027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/50: 100%|██████████| 795/795 [04:00<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50], Average Loss: 0.1031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/50: 100%|██████████| 795/795 [04:02<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50], Average Loss: 0.1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/50: 100%|██████████| 795/795 [04:01<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50], Average Loss: 0.1026\n",
      "Checkpoint saved: ./model_weights/checkpoint_linear_epoch_40.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/50: 100%|██████████| 795/795 [03:59<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50], Average Loss: 0.1026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/50: 100%|██████████| 795/795 [04:01<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50], Average Loss: 0.1015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/50: 100%|██████████| 795/795 [03:59<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50], Average Loss: 0.1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/50: 100%|██████████| 795/795 [04:02<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50], Average Loss: 0.1012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/50: 100%|██████████| 795/795 [03:59<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50], Average Loss: 0.1010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/50: 100%|██████████| 795/795 [04:01<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50], Average Loss: 0.1004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/50: 100%|██████████| 795/795 [04:00<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50], Average Loss: 0.1005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/50: 100%|██████████| 795/795 [03:59<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50], Average Loss: 0.1010\n",
      "Checkpoint saved: ./model_weights/checkpoint_linear_epoch_48.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/50: 100%|██████████| 795/795 [03:59<00:00,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50], Average Loss: 0.1009\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# # Load checkpoint if exists\n",
    "# if os.path.exists(checkpoint_path):\n",
    "#     start_epoch = load_checkpoint(gnn_model, optimizer, checkpoint_path)\n",
    "#     print(f\"Model loaded from checkpoint, starting from epoch {start_epoch + 1}\")\n",
    "# else:\n",
    "#     start_epoch = 0\n",
    "\n",
    "gnn_model.train()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(gnn_model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
    "early_stopping = EarlyStopping(patience=5, min_delta=0.001)\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        \n",
    "        # Move to cuda\n",
    "        gnndata = batch['gnndata'].to('cuda')\n",
    "        pooled_act_depths = [depth_map.cuda() for depth_map in batch['pooled_act_depths']]\n",
    "\n",
    "        output = gnn_model(gnndata.x, gnndata.edge_index, gnndata.edge_attr)\n",
    "\n",
    "        loss = 0\n",
    "        for i, node_output in enumerate(output):\n",
    "            node_output_reshaped = node_output.view(-1, output_size)\n",
    "            ground_truth = pooled_act_depths[0][i].view(-1, output_size)\n",
    "\n",
    "            normalized_output = (node_output_reshaped - node_output_reshaped.min()) / (node_output_reshaped.max() - node_output_reshaped.min() + 1e-8)\n",
    "            normalized_ground_truth = (ground_truth - ground_truth.min()) / (ground_truth.max() - ground_truth.min() + 1e-8)\n",
    "\n",
    "            loss += criterion(normalized_output, normalized_ground_truth)\n",
    "\n",
    "        loss = loss / len(output)\n",
    "#         print(loss)\n",
    "        \n",
    "#         print(loss)\n",
    "        if torch.isnan(loss):\n",
    "            print(\"Loss became NaN. Stopping training.\")\n",
    "            break\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # Free up memory\n",
    "        del gnndata, pooled_act_depths\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Print the average loss for the epoch\n",
    "    avg_loss = epoch_loss / len(train_dataloader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # early stopping\n",
    "    early_stopping(avg_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "    # Step the scheduler\n",
    "    scheduler.step(avg_loss)\n",
    "\n",
    "    # Save checkpoint every 8 epochs\n",
    "    if (epoch + 1) % 8 == 0:\n",
    "        checkpoint_name = f'./model_weights/checkpoint_linear_epoch_{epoch+1}.pth'\n",
    "        save_checkpoint(epoch, gnn_model, optimizer, checkpoint_name)\n",
    "        print(f\"Checkpoint saved: {checkpoint_name}\")\n",
    "\n",
    "    save_checkpoint(epoch, gnn_model, optimizer, checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15: 100%|██████████| 795/795 [11:48<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Average Loss: 0.1451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15: 100%|██████████| 795/795 [06:01<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/15], Average Loss: 0.1440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15: 100%|██████████| 795/795 [06:03<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/15], Average Loss: 0.1437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15: 100%|██████████| 795/795 [05:58<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/15], Average Loss: 0.1435\n",
      "Checkpoint saved: ./model_weights/checkpoint_nearest_epoch_4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15: 100%|██████████| 795/795 [05:50<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/15], Average Loss: 0.1434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15: 100%|██████████| 795/795 [05:59<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/15], Average Loss: 0.1430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15: 100%|██████████| 795/795 [05:54<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/15], Average Loss: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15: 100%|██████████| 795/795 [06:00<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/15], Average Loss: 0.1411\n",
      "Checkpoint saved: ./model_weights/checkpoint_nearest_epoch_8.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15: 100%|██████████| 795/795 [06:37<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/15], Average Loss: 0.1399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15: 100%|██████████| 795/795 [06:30<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/15], Average Loss: 0.1388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15: 100%|██████████| 795/795 [06:29<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/15], Average Loss: 0.1388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15: 100%|██████████| 795/795 [06:15<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/15], Average Loss: 0.1366\n",
      "Checkpoint saved: ./model_weights/checkpoint_nearest_epoch_12.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/15: 100%|██████████| 795/795 [06:28<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/15], Average Loss: 0.1346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/15: 100%|██████████| 795/795 [06:52<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/15], Average Loss: 0.1323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/15: 100%|██████████| 795/795 [06:04<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/15], Average Loss: 0.1316\n"
     ]
    }
   ],
   "source": [
    " checkpoint_path = './model_weights/current_nearest_checkpoint.pth'\n",
    "\n",
    "# # Load checkpoint if exists\n",
    "# if os.path.exists(checkpoint_path):\n",
    "#     start_epoch = load_checkpoint(gnn_model, optimizer, checkpoint_path)\n",
    "#     print(f\"Model loaded from checkpoint, starting from epoch {start_epoch + 1}\")\n",
    "# else:\n",
    "#     start_epoch = 0\n",
    "\n",
    "gnn_model.train()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(gnn_model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
    "early_stopping = EarlyStopping(patience=5, min_delta=0.001)\n",
    "\n",
    "num_epochs = 15\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        \n",
    "        # Move to cuda\n",
    "        gnndata = batch['gnndata'].to('cuda')\n",
    "        pooled_act_depths = [depth_map.cuda() for depth_map in batch['pooled_act_depths']]\n",
    "\n",
    "        output = gnn_model(gnndata.x, gnndata.edge_index, gnndata.edge_attr)\n",
    "\n",
    "        loss = 0\n",
    "        for i, node_output in enumerate(output):\n",
    "            node_output_reshaped = node_output.view(-1, output_size)\n",
    "            ground_truth = pooled_act_depths[0][i].view(-1, output_size)\n",
    "\n",
    "            normalized_output = (node_output_reshaped - node_output_reshaped.min()) / (node_output_reshaped.max() - node_output_reshaped.min() + 1e-8)\n",
    "            normalized_ground_truth = (ground_truth - ground_truth.min()) / (ground_truth.max() - ground_truth.min() + 1e-8)\n",
    "\n",
    "            loss += criterion(normalized_output, normalized_ground_truth)\n",
    "\n",
    "        loss = loss / len(output)\n",
    "#         print(loss)\n",
    "        \n",
    "#         print(loss)\n",
    "        if torch.isnan(loss):\n",
    "            print(\"Loss became NaN. Stopping training.\")\n",
    "            break\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # Free up memory\n",
    "        del gnndata, pooled_act_depths\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Print the average loss for the epoch\n",
    "    avg_loss = epoch_loss / len(train_dataloader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # early stopping\n",
    "    early_stopping(avg_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "    # Step the scheduler\n",
    "    scheduler.step(avg_loss)\n",
    "\n",
    "    # Save checkpoint every 8 epochs\n",
    "    if (epoch + 1) % 4 == 0:\n",
    "        checkpoint_name = f'./model_weights/checkpoint_nearest_epoch_{epoch+1}.pth'\n",
    "        save_checkpoint(epoch, gnn_model, optimizer, checkpoint_name)\n",
    "        print(f\"Checkpoint saved: {checkpoint_name}\")\n",
    "\n",
    "    save_checkpoint(epoch, gnn_model, optimizer, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1220, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Aug 14 18:41:04 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          On  |   00000000:49:00.0 Off |                   On |\n",
      "| N/A   36C    P0            107W /  300W |    6603MiB /  81920MiB |     N/A      Default |\n",
      "|                                         |                        |              Enabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| MIG devices:                                                                            |\n",
      "+------------------+----------------------------------+-----------+-----------------------+\n",
      "| GPU  GI  CI  MIG |                     Memory-Usage |        Vol|      Shared           |\n",
      "|      ID  ID  Dev |                       BAR1-Usage | SM     Unc| CE ENC DEC OFA JPG    |\n",
      "|                  |                                  |        ECC|                       |\n",
      "|==================+==================================+===========+=======================|\n",
      "|  0   10   0   0  |            3894MiB /  9728MiB    | 14      0 |  1   0    0    0    0 |\n",
      "|                  |                 2MiB / 16383MiB  |           |                       |\n",
      "+------------------+----------------------------------+-----------+-----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   10    0     955991      C   ..._and_SGG_for_MDE/.depth/bin/python3       3874MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint(10, gnn_model, optimizer, checkpoint_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "depth",
   "language": "python",
   "name": "depth"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
